replicaCount: 1
debug: false # default is true

command:
  [
    "sh",
    "-c",
    "tail -f /dev/null",
  ]

# command:
#   [
#     "sh",
#     "-c",
#     "cd /home/agent/workspace/MediNoteAI/src && make embedding_api_only",
#   ]

livenessProbe: 
  # httpGet:
  #   path: /liveness
  #   port: http
  # initialDelaySeconds: 100
  # periodSeconds: 20

readinessProbe: 
  # httpGet:
  #   path: /readiness
  #   port: http
  # initialDelaySeconds: 150
  # periodSeconds: 20

keda: 
  enabled: false

env:
  - name: PYTHONPATH
    value: "/home/agent/workspace/MediNoteAI/src/FastChat:/home/agent/workspace/MediNoteAI/src:/home/agent/workspace/generative-ai/src:/home/agent/workspace/generative-ai/test"
  - name: FASTCHAT_WORKER_API_EMBEDDING_BATCH_SIZE
    value: "1"
  - name: MODEL_NAME
    value: phi-2-orange-v2
  - name: WANDB_DISABLED
    value: "True"

image:
  repository: foundationmodels/vllm
  pullPolicy: IfNotPresent
  tag: latest


service:
  type: ClusterIP
  port: 8888
  name: encoder

ingress:
  enabled: false
  ClassName: nginx-internal
  hosts:
    - host: encoder.ai.dev1.intapp.com
      paths:
        - port: 8888
    - host: controller-encoder.ai.dev1.intapp.com
      paths:
        - port: 21001
    - host: openai-encoder.ai.dev1.intapp.com
      paths:
        - port: 8000
    - host: api-encoder.ai.dev1.intapp.com
      paths:
        - port: 5000
    - host: dashboard-encoder.ai.dev1.intapp.com
      paths:
        - port: 7860
    - host: embedding-encoder.ai.dev1.intapp.com
      paths:
        - port: 7777
  tls:
    - hosts:
        - encoder.ai.dev1.intapp.com

resources: # NC6
  requests:
    cpu: 1
    memory: 10G
  limits:
    cpu: 5
    memory: 50G
    nvidia.com/gpu: 1 # on demand I tuned it off

# resources: # NC12
#   requests:
#     cpu: 2
#     memory: 20G
#   limits:
#     cpu: 10
#     memory: 100G
#     nvidia.com/gpu: 2 # on demand I tuned it off

# resources: # NC24
#   requests:
#     cpu: 6
#     memory: 100G
#   limits:
#     cpu: 8
#     memory: 110G
#     nvidia.com/gpu: 4

# resources: # NC48
#   requests:
#     cpu: 4
#     memory: 40G
#   limits:
#     cpu: 20
#     memory: 200G
#     nvidia.com/gpu: 4 # on demand I tuned it off

# resources:
#   requests:
#     cpu: 20
#     memory: 400G
#   limits:
#     cpu: 24
#     memory: 440G
#     nvidia.com/gpu: 4


# resources:
#   requests:
#     cpu: 20
#     memory: 400G
#   limits:
#     cpu: 48
#     memory: 440G
#     nvidia.com/gpu: 4

tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "node-gpu"
    effect: "NoSchedule"
  - effect: NoSchedule
    key: kubernetes.azure.com/scalesetpriority
    operator: Equal
    value: spot
  # - effect: NoSchedule
  #   key: kubernetes.intapp.com/scalesetpriority
  #   operator: Equal
  #   value: ondemand

# affinity:
#   nodeAffinity:
#     requiredDuringSchedulingIgnoredDuringExecution:
#       nodeSelectorTerms:
#         - matchExpressions:
#             - key: kubernetes.azure.com/accelerator
#               operator: In
#               values:
#                 - nvidia
        # - matchExpressions:
        #     - key: instance-size
        #       operator: In
        #       values:
        #         - NC6                
        # - matchExpressions:
        #   - key: kubernetes.io/hostname
        #     operator: In
        #     values: 
        #     - aks-gpunc12-27063351-vmss000004


# affinity:
#   nodeAffinity:
#     requiredDuringSchedulingIgnoredDuringExecution:
#       nodeSelectorTerms:
#         - matchExpressions:
#             - key: instance-size
#               operator: In
#               values:
#                 - NV48


volumeMounts:
  - mountPath: /mnt/ai-nfs
    name: ai-nfs
  - mountPath: /home/agent/workspace
    name: ai-nfs
    subPath: workspace
  - mountPath: /mnt/models
    name: ai-nfs
    subPath: models
  - mountPath: /dev/shm
    name: dshm

volumes:
  - emptyDir:
      medium: Memory
    name: dshm
  - name: ai-nfs
    persistentVolumeClaim:
      claimName: aifile8-pvc

workingDir: /home/agent/workspace
