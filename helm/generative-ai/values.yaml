replicaCount: 1
debug: true # keep it as a default
command: ["sh", "-c", "tail -f /dev/null"] 

image:
  repository: foundationmodels/vllm
  pullPolicy: IfNotPresent
  tag: latest


workingDir: /home/agent/workspace/

livenessProbe:
  httpGet:
    path: /liveness
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
readinessProbe:
  httpGet:
    path: /readiness
    port: http
  initialDelaySeconds: 25
  periodSeconds: 10
nameOverride: ""
fullnameOverride: ""
serviceAccount:
  create: true
  annotations: {}
  name: ""

labels:
  Product: AI
  ProductComponents: generative-ai
  Team: AI


podSecurityContext:
  runAsUser: 1000
  runAsGroup: 100

securityContext:
  privileged: false
  runAsUser: 1000
  runAsGroup: 100

service:
  type: ClusterIP
  port: 8888
  name: generative-ai


resources:
  requests:
    cpu: 1
    memory: 2G
  limits: null

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

env:
  - name: PYTHONPATH
    value: "/home/agent/workspace/generative-ai/src:/home/agent/workspace/generative-ai/tests"
  - name: LOGS_FILE
    value: "/home/agent/workspace/generative-ai/logs/generative-ai.log"
  - name: FASTCHAT_WORKER_API_EMBEDDING_BATCH_SIZE
    value: "1"
  - name: OPENAI_API_KEY
    value: "empty"


volumeMounts:
  - name: ai-nfs
    subPath: models
  - mountPath: /home/agent/workspace
    name: ai-nfs
    subPath: workspace
  - mountPath: /home/agent/.vscode-server
    name: ai-nfs
    subPath: vscode-server
  # Shared memory
  - name: dshm
    mountPath: /dev/shm

volumes:
  - name: dshm
    emptyDir:
      medium: Memory
  - name: ai-nfs
    persistentVolumeClaim:
      claimName: ai-nfs



