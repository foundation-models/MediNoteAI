{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "python",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "internalConsole",
            "justMyCode": false
        },
        {
            "name": "trainer",
            "type": "python",
            "request": "launch",
            "program": "/home/agent/workspace/generative/src/api/fast_api_mini.py",
            "console": "internalConsole",
            "justMyCode": false
        },
        {
            "name": "uvicorn",
            "type": "python",
            "request": "launch",
            "module": "uvicorn",
            "cwd": "${workspaceFolder}/rag/dms",
            "args": ["dms.asgi:application","--host","0.0.0.0","--port","8888","--reload","--workers","2"],
            "console": "internalConsole",
            "justMyCode": false
        },
        {
            "name": "trainiong-ui",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}/training-ui",
            "program": "main.py",
            "console": "internalConsole",
            "justMyCode": false
        },
        {
            "name": "clip-fine-tuning",
            "type": "python",
            "request": "launch",
            "cwd": "/mnt/ai-nfs/datasets",
            "program": "${workspaceFolder}/image2text/src/training/fine_tuning.py",
            "console": "internalConsole",
            "justMyCode": false
        },
        {
            "name": "python Terminal",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false
        },
        {
            "name": "gradio",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "internalConsole",
            "justMyCode": false,
            "args": [
                "--controller-url",
                "https://controller.ai.dev1.intapp.com",
                "--model-list-mode",
                "reload"
            ],
        },
        {
            "name": "webui",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}/MediNoteAI/src/text-generation-webui",
            "program": "server.py",
            "console": "internalConsole",
            "justMyCode": false,
            "args": [
                "--share",
                "--trust-remote-code"
            ]
        },
        {
            "name": "model_worker", // Remember to set USE_VLLM=False
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}/generative-ai/src",
            "program": "${workspaceFolder}/generative-ai/src/fastchat/serve/model_worker.py",
            "console": "internalConsole",
            "justMyCode": false,
            "args": [
                "--no-register",
                "--trust-remote-code",
                "--api", //launch 5000 port form webui
                "--listen", //makes 7860 port listen on 0.0.0.0
                // "--load-in-8bit",//dont use it for llama-2-7b
                // "--load-in-4bit", // for lora training with hf models 
                // "--dtype", // has to add this
                // "half", // (choose from 'auto', 'half', 'bfloat16', 'float') use half fot the case of bf16
                "--model-dir",
                // "/mnt/models-nfs/models",
                "/mnt/ai-nfs/models",
                // "/home/agent/models",
                "--model",
                // "bge-base-en-v1.5",
                // "zephyr-7b-beta-patient-doctor", 
                // "zephyr-7b-beta-patient-doctor-repeat", 
                // "sqlcoder-7b", 
                // "sqlcoder2",
                // "phi-2",
                "phi-2-doctor-patient-repeat",
                // "zephyr-7b-beta", 
                // "nsql-350M",
                // "zephyr-7b-alphad_primery_entities_800_limited_fine_tuned",
                // "--lora-dir",
                // "/home/agent/workspace/loras",
                // "--lora",
                // "patient-physican",
                // "sql7bInst",
                "--conv-template",
                "mistral",
                // "llama-2", // should match conv.name in the adapter
                // "zephyr", // should match conv.name in the adapter
                "--port",
                "8888",
                "--controller-address",
                "https://controller-llama.ai.dev1.intapp.com",
                "--worker-address",
                "https://llama.ai.dev1.intapp.com",
                "--device",
                "cuda",
                "--num-gpus",
                "1",
                "--model-names",
                // "ner"
                "llama,gpt-3.5-turbo,text-davinci-003,text-embedding-ada-002",
                "--use_fast",
                "True",
                // "--embedding-model-dir",
                // "/mnt/ai-nfs/models/bge-small-en-v1.5",
                // "--embedding-model-names",
                // "text-embedding",
            ],
        },
        {
            "name": "lora_trainer", // Remember to set USE_VLLM=False
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}/generative-ai/src",
            "program": "${workspaceFolder}/generative-ai/src/training/lora_trainer.py",
            "console": "internalConsole",
            "justMyCode": false,
            "args": [
                "--no-register",
                "--trust-remote-code",
                "--load-in-4bit", // for lora training with hf models 
                "--model-dir",
                "/mnt/models-nfs/models",
                "--model",
                "CodeLlama-7b-Instruct-hf",
                "--device",
                "cuda",
                "--num-gpus",
                "1",
            ],
        },
        {
            "name": "vllm",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}/generative-ai/src",
            "program": "${workspaceFolder}/generative-ai/src/fastchat/serve/model_worker.py",
            "console": "internalConsole",
            "justMyCode": false,
            "args": [
                "--no-register",
                "--trust-remote-code",
                "--use_vllm",
                "True",
                "--dtype", // has to add this
                "float16", // "half", // (choose from 'auto', 'half', 'bfloat16', 'float16')                    "--trust-remote-code",
                // "--load-in-8bit",//dont use it for llama-2-7b
                // "--load-in-8bit",//dont use it for llama-2-7b
                // "--loader",
                // "transformers",
                "--model-path",
                // "/mnt/models-nfs/models/CodeLlama-7b-hf-flash",
                // "/mnt/ai-nfs/models/zephyr-7b-alphad_primery_entities_800_limited_fine_tuned",
                "/mnt/ai-nfs/models/zephyr-7b-beta-patient-doctor-repeat",
                "--conv-template",
                "mistral",
                // "llama-2", // should match conv.name in the adapter
                "--port",
                "8888",
                "--controller-address",
                "https://controller-llama.ai.dev1.intapp.com",
                "--worker-address",
                "https://llama.ai.dev1.intapp.com",
                "--num-gpus",
                "1",
                // "--model-name",
                // // "CodeLlama-7b-Instruct-hf",
                // "Mistral-7B-Instruct-v0.1",
                // "Mistral-7B-OpenOrca-SQL_GQL-finetuned", // uses bf16
                "--model-names",
                // "ner"
                "llama,gpt-3.5-turbo,text-davinci-003,text-embedding-ada-002"
                // "tulpar-7b-v0,gpt-3.5-turbo,text-davinci-003,text-embedding-ada-002"
            ],
        },
        {
            "name": "openai",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/generative-ai/src/fastchat/serve/openai_api_server.py",
            "console": "internalConsole",
            "justMyCode": false,
            "args": [
                "--port",
                "8888",
                "--controller-address",
                "https://controller-llama-2.ai.dev1.intapp.com"
            ],
        },
        {
            "name": "openaixx",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/generative-ai/src/openai_api.py",
            "console": "internalConsole",
            "justMyCode": false,
            "args": [
                "--input",
                "/home/agent/workspace/FLARE/data/2wikimultihopqa",
                "--output",
                "/mnt/ai-nfs/dataset/flare/output",
            ]
        },
        {
            "name": "DeepSpeed",
            "type": "python",
            "request": "launch",
            "program": "/venv/bin/deepspeed",
            "justMyCode": true,
            "console": "internalConsole",
            "args": [
                "generative-ai/src/fastchat/train/train_lora.py",
                "--model_name_or_path",
                // "/mnt/models-nfs/models/CodeLlama-7b-Instruct-hf",
                "/mnt/models-nfs/models/falcon-rw-1b",
                // "/mnt/models-nfs/models/Llama-2-7b-hf",
                "--lora_r",
                "32",
                "--lora_alpha",
                "64",
                "--lora_dropout",
                "0.05",
                "--data_path",
                "/home/agent/workspace/generative-ai/src/training/datasets/test2.json",
                // "--eval_data_path",
                // "/home/agent/workspace/finance-vicuna-100.json", // "/home/agent/workspace/finance-100.json",
                "--output_dir",
                "./checkpoints",
                "--num_train_epochs",
                "1",
                // "--fp16",
                // "True",
                // "--per_device_train_batch_size",
                // "2",
                // "--per_device_eval_batch_size",
                // "2",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "1",
                "--gradient_accumulation_steps",
                "1",
                "--evaluation_strategy",
                "steps",
                "--eval_steps",
                "100 ",
                "--save_strategy",
                "steps",
                "--save_steps",
                "200",
                "--save_total_limit",
                "2",
                "--learning_rate",
                "2e-5",
                "--weight_decay",
                "0.",
                "--warmup_ratio",
                "0.03",
                "--lr_scheduler_type",
                "cosine",
                "--logging_strategy",
                "steps",
                "--logging_steps",
                "1",
                "--model_max_length",
                "2048",
                "--q_lora",
                "True",
                "--gradient_checkpointing",
                "True",
                "--flash_attn",
                "False",
                "--ddp_find_unused_parameters",
                "False"
            ]
        },
        {
            "name": "DeepSpeed2",
            "type": "python",
            "request": "launch",
            // "program": "/venv/bin/deepspeed",
            "program": "/usr/local/bin/deepspeed",
            "justMyCode": true,
            "console": "internalConsole",
            "args": [
                "generative-ai/src/fastchat/train/train_lora2.py",
                "--model_name_or_path",
                // "/mnt/models-nfs/models/CodeLlama-7b-Instruct-hf",
                "/home/agent/workspace/MediNoteAI/src/text-generation-webui/models/phi-1_5",
                // "/mnt/models-nfs/models/Llama-2-7b-hf",
                "--lora_r",
                "8",
                "--lora_alpha",
                "16",
                "--lora_dropout",
                "0.05",
                "--data_path",
                "/home/agent/workspace/MediNoteAI/src/text-generation-webui/training/datasets/huggingface/BI55-MedText/completion_training_text_200.json",
                // "--eval_data_path",
                // "/home/agent/workspace/finance-vicuna-100.json", // "/home/agent/workspace/finance-100.json",
                "--output_dir",
                "/home/agent/workspace/MediNoteAI/src/text-generation-webui/loras/BI55-MedText",
                "--num_train_epochs",
                "1",
                "--fp16",
                "True",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "1",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "1",
                "--gradient_accumulation_steps",
                "1",
                "--evaluation_strategy",
                "steps",
                "--eval_steps",
                "100 ",
                "--save_strategy",
                "steps",
                "--save_steps",
                "200",
                "--save_total_limit",
                "2",
                "--learning_rate",
                "2e-5",
                "--weight_decay",
                "0.",
                "--warmup_ratio",
                "0.03",
                "--lr_scheduler_type",
                "cosine",
                "--logging_strategy",
                "steps",
                "--logging_steps",
                "1",
                "--model_max_length",
                "2048",
                "--q_lora",
                "True",
                "--gradient_checkpointing",
                "False",
                "--flash_attn",
                "False",
                "--ddp_find_unused_parameters",
                "False",
                "--deepspeed",
                "/home/agent/workspace/MediNoteAI/src/FastChat/playground/deepspeed_config_s2.json"
            ]
        },
        {
            "name": "finetune",
            "type": "python",
            "request": "launch",
            // "program": "${workspaceFolder}/generative-ai/src/fastchat/train/train_lora2.py",
            "program": "${workspaceFolder}/MediNoteAI/src/medinote/finetune/finetune_lora.py",
            "justMyCode": true,
            "console": "internalConsole",
            "args": [
                "--model_name_or_path",
                // "/mnt/models-nfs/models/CodeLlama-7b-Instruct-hf",
                "/home/agent/workspace/MediNoteAI/src/text-generation-webui/models/phi-1_5",
                // "/mnt/models-nfs/models/Llama-2-7b-hf",
                "--lora_r",
                "8",
                "--lora_alpha",
                "16",
                "--lora_dropout",
                "0.05",
                "--data_path",
                "/home/agent/workspace/MediNoteAI/src/text-generation-webui/training/datasets/huggingface/BI55-MedText/completion_training_text_200.json",
                // "--eval_data_path",
                // "/home/agent/workspace/finance-vicuna-100.json", // "/home/agent/workspace/finance-100.json",
                "--output_dir",
                "/home/agent/workspace/MediNoteAI/src/text-generation-webui/loras/BI55-MedText",
                "--num_train_epochs",
                "1",
                "--fp16",
                "True",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "1",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "1",
                "--gradient_accumulation_steps",
                "1",
                "--evaluation_strategy",
                "steps",
                "--eval_steps",
                "100 ",
                "--save_strategy",
                "steps",
                "--save_steps",
                "200",
                "--save_total_limit",
                "2",
                "--learning_rate",
                "2e-5",
                "--weight_decay",
                "0.",
                "--warmup_ratio",
                "0.03",
                "--lr_scheduler_type",
                "cosine",
                "--logging_strategy",
                "steps",
                "--logging_steps",
                "1",
                "--model_max_length",
                "2048",
                "--q_lora",
                "True",
                "--gradient_checkpointing",
                "False",
                "--flash_attn",
                "True",
                "--flash_rotary",
                "True",
                // "fused_dense",
                // "True",
                // "low_cpu_mem_usage",
                // "False",
                "--ddp_find_unused_parameters",
                "False",
                "--lora_target_modules_str",
                "Wqkv,out_proj"
            ]
        },
        {
            "name": "finetune2",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/generative-ai/src/fastchat/train/overwrite.py",
            "justMyCode": true,
            "console": "internalConsole",
        },
        {
            "name": "ludwig", 
            "type": "python",
            "request": "launch",
            // "program": "${workspaceFolder}/generative-ai/src/ludwig/serve.py",
            // "program": "${workspaceFolder}/generative-ai/src/ludwig/preprocess.py",
            "program": "${workspaceFolder}/generative-ai/tests/util/train_via_ludwig.py",
            "console": "internalConsole",
            "justMyCode": false,
            "args": []
        }
    ]
}