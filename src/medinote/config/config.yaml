function:
  # Function to be used for the prediction
  augment_function: medinote.augmentation.synthetic_sql.query_llm
  pre_screening_function: medinote.augmentation.synthetic_sql.query_llm_for_dataframe
  screening_function: xxxx
  embedding_function:  medinote.curation.rest_clients.generate_via_rest_client
  filtering_function:  medinote.augmentation.synthetic_sql.filtering_sql_queries


vllm_openai_api:
  payload_template: '{{
   "model": "/mnt/models/Llama-3-8B-Instruct-GPTQ-8-Bit",
   "messages": [
       {{"role": "system", "content": "You are a helpful assistant."}},
       {{"role": "user", "content": "{prompt}"}}
       ],
   "max_tokens": 2000,
   "stop_token_ids":[128001,128009]
    }}'



refine_workflow:
  input_path: /mnt/input.parquet
  output_path: /mnt/output
  column: result
  postprocess_column: api-check
  start_index: 0
  bad_df_length: 100000
  combined_df_size: 400
  input_column: output

augmentation:
  prompt_template: "### System:
      ${instruction}

      ### User:
      ${input}

      --- Attributes ---:
      ${attributes}

      ### Assistant:
      "
  payload_template: '{
            "echo": false,
            "max_new_tokens": 1600,
            "do_sample": true,
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "repetition_penalty": 1.1,
            "stop": [
                "###",
                "<|im_start|>"
            ],
            "prompt": "${prompt}"
        }'
  inference_response_limit: 100
  instruction: Generate a list of similar queries based on the given original query. Modify the original query by changing, adding, or substituting specific attributes and values as outlined. Ensure that each new query is coherent and reflects the intended modifications.
  output_column: output
  inference_url: 'http://phi-generative-ai:8888/worker_generate'
  output_separator: '\n'
  
  

archive:
  prompt_template: Generate ${results_count} synthetic SQL queries for the '${table_name}' table with fields ${field_names} based on the base query '${sql_query}' focusing on simple structures (no joins subqueries grouping; include sorting and counting) and format the output as a CSV with each line containing one SQL query.
  instruction: Generate a specified number of synthetic SQL queries based on a given table and its fields and output them in a CSV format with each query on a separate line.

restful-url:


embedding:
  embedding_vector_dimnesion: 1024
  OPENSEARCH_HOST: opensearch-cluster-master
  OPENSEARCH_INDEX: api-filtered-queries
  embedding_url: http://encoder-generative-ai:8888/worker_get_embeddings
  text_field: content
  embedding_field: embedding
  column2embed: output
  # chunk_size: 100

screening:
  screening_column: screening
  api_response_item_count: totalRecords
  prompt_template: "### ${instruction}
    based on the following samples:
    ${samples}
    ### Input: ${input}
    ### Output:
      "
  payload_template: '{
            "echo": false,
            "max_new_tokens": 1600,
            "do_sample": true,
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "repetition_penalty": 1.1,
            "stop": [
                "### End",
                "### END",
                "###\n",
                "<|im_start|>"
            ],
            "prompt": "${prompt}"
        }'
  inference_response_limit: 100
  instruction: You are a SQL master and your job is to convert questions to SQL queries.
  input_column: output
  output_column: api_response
  inference_url: 'http://mistral-generative-ai:8888/worker_generate'
  output_separator: '\n'
  table_fields_mapping_file: /mnt/datasets/sql_gen/schema.yaml

gte_embedding:
  input_path: /home/agent/workspace/MediNoteAI/datasets/synthetic_questions/samples/text_classification_sample.csv
  output_path: /home/agent/workspace/MediNoteAI/datasets/text_classification_sample_populated.parquet
  instruct: Find the sentiment of each sentence, answer it as positive or negative.

  inference_url: https://gte-embedding.ai.dev1.intapp.com/api/embeddings
  response_column: embedding

  prompt_template: |
    {embedding_input}

  payload_template: |
    {{
      "model": "rjmalagon/gte-qwen2-7b-instruct-embed-f16",
      "prompt": "{prompt}"
    }}

cross_score_calulation:
  input_path: /home/agent/workspace/MediNoteAI/datasets/text_classification_sample_populated.parquet
  output_path: /home/agent/workspace/MediNoteAI/datasets/text_classification_sample_cross_scored.parquet